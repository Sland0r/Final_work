{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from diffusion_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5,), std=(0.5,))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "transformerr = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = list(range(1,1001))\n",
    "beta = dict()\n",
    "for t in step:\n",
    "    beta[t] = round(t * 0.0199 / 999 + (0.02 - 0.0199 / 999 * 1000), 15) # beta = at + b\n",
    "alpha = dict()\n",
    "alpha[1] = 1 - beta[1]\n",
    "for t in step[1:]:\n",
    "    alpha[t] = alpha[t-1] * (1 - beta[t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "T = dict()\n",
    "for t in step:\n",
    "    T[t] = -1/2 * math.log(alpha[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.058856771206552"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[1000] #collapse time experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speciation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FashionMNIST('~/.pytorch/FashionMNIST_data/', train=True, download=True, transform=transformerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3814)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(trainset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = trainset.targets == 2\n",
    "mask_2 = trainset.targets == 7\n",
    "mask = mask_1 | mask_2\n",
    "trainset = torch.utils.data.Subset(trainset, torch.where(mask)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store tensors\n",
    "tensor_list = []\n",
    "\n",
    "# Loop through the dataset and collect the tensors\n",
    "for x in range(len(trainset)):\n",
    "    tensor_list.append(trainset[x][0])\n",
    "    \n",
    "\n",
    "# Concatenate all tensors at once\n",
    "dataset = torch.cat(tensor_list, dim=0)\n",
    "\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = dataset[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2722), tensor(0.2709))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(dataset), torch.mean(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset - torch.mean(dataset)\n",
    "reduced = reduced - torch.mean(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = []\n",
    "for i in range(len(dataset)):\n",
    "    row.append(dataset[i].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_r = []\n",
    "for i in range(len(reduced)):\n",
    "    row_r.append(reduced[i].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12000, 784]), torch.Size([10000, 784]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(row).shape, torch.Tensor(row_r).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = torch.transpose(torch.Tensor(row),0,1)\n",
    "row_r = torch.transpose(torch.Tensor(row_r),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cd/sr6rtt2j1rqdn0jdyblt3ztm0000gn/T/ipykernel_53970/2774834625.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  C = torch.cov(torch.tensor(row))\n",
      "/var/folders/cd/sr6rtt2j1rqdn0jdyblt3ztm0000gn/T/ipykernel_53970/2774834625.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  C_r = torch.cov(torch.tensor(row_r))\n"
     ]
    }
   ],
   "source": [
    "C = torch.cov(torch.tensor(row))\n",
    "C_r = torch.cov(torch.tensor(row_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 784]), torch.Size([784, 784]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape, C_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    L, _ = torch.linalg.eigh(C, UPLO=\"L\")\n",
    "    L_r, _ = torch.linalg.eigh(C_r, UPLO=\"L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 -> 1: 31.77\n",
    "\n",
    "-1 -> 1: 127.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(31.7777), tensor(31.6263))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[-1], L_r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7294)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_s = 0.5 * np.log(L[-1])\n",
    "t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_time = min(T, key=lambda k: abs(T[k]-t_s))\n",
    "mapped_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "from torchvision import datasets, transforms\n",
    "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', train=True, download=True, transform=transformerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_n (N, mask):\n",
    "    n = 0\n",
    "    for i in range(len(mask)):\n",
    "        if mask[i]:\n",
    "            n += 1\n",
    "        if n == N:\n",
    "            for j in range(i+1, len(mask)):\n",
    "                mask[j] = False\n",
    "            break\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = dataset.targets == 0\n",
    "first_n(100, mask_1)\n",
    "mask_2 = dataset.targets == 7\n",
    "first_n(100, mask_2)\n",
    "mask = mask_1 | mask_2\n",
    "dataset = torch.utils.data.Subset(dataset, torch.where(mask)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor()\n",
    "for x in range(len(dataset)):\n",
    "    a = torch.cat((a, dataset[x][0]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 28, 28])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def P(t, x):\n",
    "    #t = T[t]\n",
    "    d = 28 * 28\n",
    "    logs = []\n",
    "    for i in range(a.shape[0]):\n",
    "        logs.append(np.log(1 / a.shape[0]) - d/2 * np.log( 2 * torch.pi * (1 - torch.e **(-2*t)) ) - 0.5 * torch.norm(x - a[i]*torch.e**(-t))**2 / (1-torch.e**(0-2*t)))\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-21.1284),\n",
       " tensor(-299.4906),\n",
       " tensor(-99.4059),\n",
       " tensor(-353.8616),\n",
       " tensor(-249.1019),\n",
       " tensor(-159.3817),\n",
       " tensor(-366.3493),\n",
       " tensor(-318.9525),\n",
       " tensor(-191.6410),\n",
       " tensor(-324.5208),\n",
       " tensor(-253.8734),\n",
       " tensor(-212.1662),\n",
       " tensor(-378.3724),\n",
       " tensor(-260.0832),\n",
       " tensor(-316.6208),\n",
       " tensor(-182.4068),\n",
       " tensor(-325.6183),\n",
       " tensor(-172.0652),\n",
       " tensor(-366.4845),\n",
       " tensor(-256.1553),\n",
       " tensor(-322.3724),\n",
       " tensor(-163.1113),\n",
       " tensor(-333.0019),\n",
       " tensor(-320.7443),\n",
       " tensor(-309.5170),\n",
       " tensor(-364.6244),\n",
       " tensor(-214.9875),\n",
       " tensor(-160.2290),\n",
       " tensor(-99.8308),\n",
       " tensor(-336.0434),\n",
       " tensor(-329.6689),\n",
       " tensor(-333.2940),\n",
       " tensor(-339.9143),\n",
       " tensor(-323.4059),\n",
       " tensor(-228.1105),\n",
       " tensor(-342.8399),\n",
       " tensor(-398.6082),\n",
       " tensor(-213.8842),\n",
       " tensor(-308.4899),\n",
       " tensor(-152.8037),\n",
       " tensor(-316.9795),\n",
       " tensor(-388.8369),\n",
       " tensor(-287.5333),\n",
       " tensor(-315.1446),\n",
       " tensor(-254.4215),\n",
       " tensor(-335.5030),\n",
       " tensor(-366.6305),\n",
       " tensor(-318.6136),\n",
       " tensor(-321.3599),\n",
       " tensor(-302.5354),\n",
       " tensor(-315.9307),\n",
       " tensor(-314.6318),\n",
       " tensor(-216.5980),\n",
       " tensor(-351.6885),\n",
       " tensor(-351.9722),\n",
       " tensor(-336.9243),\n",
       " tensor(-326.7251),\n",
       " tensor(-317.6555),\n",
       " tensor(-349.1717),\n",
       " tensor(-282.6066),\n",
       " tensor(-366.4113),\n",
       " tensor(-174.4323),\n",
       " tensor(-193.6460),\n",
       " tensor(-306.8783),\n",
       " tensor(-111.1998),\n",
       " tensor(-320.8680),\n",
       " tensor(-324.4889),\n",
       " tensor(-218.1864),\n",
       " tensor(-363.4426),\n",
       " tensor(-109.1844),\n",
       " tensor(-334.8325),\n",
       " tensor(-284.9080),\n",
       " tensor(-335.4330),\n",
       " tensor(-319.3657),\n",
       " tensor(-131.9365),\n",
       " tensor(-343.3028),\n",
       " tensor(-269.9422),\n",
       " tensor(-293.4333),\n",
       " tensor(-372.5405),\n",
       " tensor(-345.7000),\n",
       " tensor(-133.5275),\n",
       " tensor(-323.0466),\n",
       " tensor(-345.2176),\n",
       " tensor(-408.5141),\n",
       " tensor(-149.0629),\n",
       " tensor(-259.4763),\n",
       " tensor(-222.1721),\n",
       " tensor(-300.9011),\n",
       " tensor(-332.4492),\n",
       " tensor(-259.9340),\n",
       " tensor(-210.1974),\n",
       " tensor(-155.5003),\n",
       " tensor(-249.5515),\n",
       " tensor(-230.9642),\n",
       " tensor(-382.4618),\n",
       " tensor(-290.0150),\n",
       " tensor(-340.0118),\n",
       " tensor(-175.8528),\n",
       " tensor(-403.8167),\n",
       " tensor(-332.2101),\n",
       " tensor(-265.5918),\n",
       " tensor(-332.2909),\n",
       " tensor(-304.1756),\n",
       " tensor(-341.9975),\n",
       " tensor(-384.1654),\n",
       " tensor(-149.1724),\n",
       " tensor(-279.7018),\n",
       " tensor(-352.9406),\n",
       " tensor(-271.4215),\n",
       " tensor(-299.2527),\n",
       " tensor(-269.2722),\n",
       " tensor(-259.0364),\n",
       " tensor(-355.9099),\n",
       " tensor(-338.6918),\n",
       " tensor(-318.8593),\n",
       " tensor(-149.4594),\n",
       " tensor(-315.5718),\n",
       " tensor(-332.0226),\n",
       " tensor(-307.7064),\n",
       " tensor(-321.6045),\n",
       " tensor(-219.1857),\n",
       " tensor(-348.7826),\n",
       " tensor(-322.1095),\n",
       " tensor(-227.1865),\n",
       " tensor(-336.3092),\n",
       " tensor(-366.5192),\n",
       " tensor(-354.6409),\n",
       " tensor(-230.1700),\n",
       " tensor(-328.4068),\n",
       " tensor(-319.5735),\n",
       " tensor(-61.5681),\n",
       " tensor(-339.3272),\n",
       " tensor(-343.1838),\n",
       " tensor(-303.9005),\n",
       " tensor(-368.0724),\n",
       " tensor(-189.7360),\n",
       " tensor(-196.9503),\n",
       " tensor(-232.8491),\n",
       " tensor(-303.4902),\n",
       " tensor(-341.0138),\n",
       " tensor(-104.7187),\n",
       " tensor(-335.8749),\n",
       " tensor(-359.6588),\n",
       " tensor(-152.4480),\n",
       " tensor(-217.5556),\n",
       " tensor(-278.0588),\n",
       " tensor(-143.9481),\n",
       " tensor(-283.2903),\n",
       " tensor(-309.1595),\n",
       " tensor(-390.4215),\n",
       " tensor(-335.9271),\n",
       " tensor(-376.2408),\n",
       " tensor(-176.0059),\n",
       " tensor(-172.4879),\n",
       " tensor(-222.0089),\n",
       " tensor(-336.6469),\n",
       " tensor(-315.5945),\n",
       " tensor(-356.5378),\n",
       " tensor(-310.2291),\n",
       " tensor(-166.0737),\n",
       " tensor(-327.4643),\n",
       " tensor(-124.8968),\n",
       " tensor(-264.7060),\n",
       " tensor(-350.8829),\n",
       " tensor(-375.5513),\n",
       " tensor(-334.6211),\n",
       " tensor(-149.2704),\n",
       " tensor(-342.2151),\n",
       " tensor(-393.8227),\n",
       " tensor(-351.1232),\n",
       " tensor(-187.3215),\n",
       " tensor(-359.3274),\n",
       " tensor(-188.8976),\n",
       " tensor(-305.0019),\n",
       " tensor(-195.5797),\n",
       " tensor(-86.9089),\n",
       " tensor(-360.4622),\n",
       " tensor(-172.9022),\n",
       " tensor(-383.3656),\n",
       " tensor(-335.9680),\n",
       " tensor(-307.1568),\n",
       " tensor(-359.0687),\n",
       " tensor(-349.7977),\n",
       " tensor(-275.0035),\n",
       " tensor(-372.7015),\n",
       " tensor(-293.3349),\n",
       " tensor(-374.8193),\n",
       " tensor(-371.6880),\n",
       " tensor(-146.5290),\n",
       " tensor(-321.4839),\n",
       " tensor(-144.6187),\n",
       " tensor(-261.2662),\n",
       " tensor(-250.8746),\n",
       " tensor(-199.6287),\n",
       " tensor(-217.9504),\n",
       " tensor(-317.0589),\n",
       " tensor(-241.7477),\n",
       " tensor(-237.8891),\n",
       " tensor(-219.8104),\n",
       " tensor(-270.0069)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(0.09, a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "t =0.09\n",
    "x = a[0]\n",
    "d = 28 * 28\n",
    "lg = np.log(1 / a.shape[0]) - d/2 * np.log( 2 * torch.pi * (1 - torch.e **(-2*t)) ) - 0.5 * torch.norm(x - a[0]*torch.e**(-t))**2 / (1-torch.e**(0-2*t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-21.1284)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(1,a[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1189247332798637"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from diffusion_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog  truck truck deer \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# Download and load the training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the classes in CIFAR-10\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# Print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('automobile', 'horse')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[1], classes[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Things Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextUnet(nn.Module):\n",
    "    def __init__(self, in_channels, n_feat=256, n_cfeat=10, height=32):  # cfeat - context features\n",
    "        super(ContextUnet, self).__init__()\n",
    "\n",
    "        # number of input channels, number of intermediate feature maps and number of classes\n",
    "        self.in_channels = in_channels\n",
    "        self.n_feat = n_feat\n",
    "        self.n_cfeat = n_cfeat\n",
    "        self.h = height  #assume h == w. must be divisible by 4, so 28,24,20,16...\n",
    "\n",
    "        # Initialize the initial convolutional layer\n",
    "        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True) # 3x3, padding 1. applies 2 times. outputs 256 channels\n",
    "\n",
    "        # Initialize the down-sampling path of the U-Net with two levels\n",
    "        self.down1 = UnetDown(n_feat, n_feat)        # down1 #[batch, 256, 16, 16]\n",
    "        self.down2 = UnetDown(n_feat, 2 * n_feat)    # down2 #[batch, 256, 8,  8]\n",
    "        self.down3 = UnetDown(2 * n_feat, 2 * n_feat)    # down3 #[bacth, 256, 4,  4]\n",
    "\n",
    "\n",
    "         # original: self.to_vec = nn.Sequential(nn.AvgPool2d(7), nn.GELU())\n",
    "        self.to_vec = nn.Sequential(nn.AvgPool2d((4)), nn.GELU())\n",
    "\n",
    "        # Embed the timestep and context labels with a one-layer fully connected neural network\n",
    "        self.timeembed1 = EmbedFC(1, 2*n_feat)\n",
    "        self.timeembed2 = EmbedFC(1, 2*n_feat)\n",
    "        self.timeembed3 = EmbedFC(1, n_feat)\n",
    "        #self.contextembed1 = EmbedFC(n_cfeat, 2*n_feat)\n",
    "        #self.contextembed2 = EmbedFC(n_cfeat, 2*n_feat)\n",
    "        #self.contextembed3 = EmbedFC(n_cfeat, n_feat)\n",
    "\n",
    "        # Initialize the up-sampling path of the U-Net with three levels\n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, self.h//8, self.h//8), # up-sample\n",
    "            nn.GroupNorm(8, 2 * n_feat), # normalize\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.up1 = UnetUp(4 * n_feat, 2 * n_feat)\n",
    "        self.up2 = UnetUp(4 * n_feat, n_feat)\n",
    "        self.up3 = UnetUp(2 * n_feat, n_feat)\n",
    "\n",
    "        # Initialize the final convolutional layers to map to the same number of channels as the input image\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(2 * n_feat, n_feat, 3, 1, 1), # reduce number of feature maps   #in_channels, out_channels, kernel_size, stride=1, padding=0\n",
    "            nn.GroupNorm(8, n_feat), # normalize\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_feat, self.in_channels, 3, 1, 1), # map to same number of channels as input\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, c=None):\n",
    "        \"\"\"\n",
    "        x : (batch, n_feat, h, w) : input image\n",
    "        t : (batch, n_cfeat)      : time step\n",
    "        c : (batch, n_classes)    : context label\n",
    "        \"\"\"\n",
    "        # x is the input image, c is the context label, t is the timestep, context_mask says which samples to block the context on\n",
    "        #print(f\"Input shape: {x.shape}\")\n",
    "        #we begin 3x32x32\n",
    "        x = self.init_conv(x) # feat x 32 x 32\n",
    "        #print(f\"After init_conv shape: {x.shape}\")\n",
    "        down1 = self.down1(x) # feat x 16 x 16\n",
    "        #print(f\"After down1 shape: {down1.shape}\")\n",
    "        down2 = self.down2(down1) # 2feat x 8 x 8\n",
    "        #print(f\"After down2 shape: {down2.shape}\")\n",
    "        down3 = self.down3(down2) # 2feat x 4 x 4\n",
    "        #print(f\"After down3 shape: {down3.shape}\")\n",
    "\n",
    "        hiddenvec = self.to_vec(down3) #IT IS NOT A VECTOR, WE HAVE 2FEAT X 4 X 4\n",
    "        #print(f\"Hidden vector shape: {hiddenvec.shape}\")\n",
    "\n",
    "        # mask out context if context_mask == 1\n",
    "        if c is None:\n",
    "            c = torch.zeros(x.shape[0], self.n_cfeat).to(x) # (batch, cfeat)\n",
    "\n",
    "        # embed context and timestep\n",
    "        #cemb1 = self.contextembed1(c).view(-1, self.n_feat * 2, 1, 1)     # (batch, 2*n_feat, 1,1)\n",
    "        temb1 = self.timeembed1(t).view(-1, self.n_feat * 2, 1, 1)\n",
    "        #cemb2 = self.contextembed2(c).view(-1, self.n_feat * 2, 1, 1)\n",
    "        temb2 = self.timeembed2(t).view(-1, self.n_feat * 2, 1, 1)\n",
    "        #cemb3 = self.contextembed3(c).view(-1, self.n_feat , 1, 1)\n",
    "        temb3 = self.timeembed3(t).view(-1, self.n_feat , 1, 1)\n",
    "\n",
    "\n",
    "        #print(f\"uunet forward: cemb1 {cemb1.shape}. temb1 {temb1.shape}, cemb2 {cemb2.shape}. temb2 {temb2.shape}\")\n",
    "\n",
    "\n",
    "        # up1 = self.up0(hiddenvec)\n",
    "        # up2 = self.up1(cemb1*up1 + temb1, down2)  # add and multiply embeddings\n",
    "        # up3 = self.up2(cemb2*up2 + temb2, down1)\n",
    "        # print(f\"Shape of up3 before final concat: {up3.shape}\")\n",
    "        # print(f\"Shape of x before final concat: {x.shape}\")\n",
    "        # # Ensure up3 and x have the same height and width before concatenation\n",
    "        # if up3.shape[2:] != x.shape[2:]:\n",
    "        #     up3 = nn.functional.interpolate(up3, size=x.shape[2:], mode='nearest')\n",
    "        up1 = self.up0(hiddenvec)\n",
    "        #print(f\"After up0 shape: {up1.shape}\")\n",
    "\n",
    "        up2 = self.up1(up1 + temb1, down3)\n",
    "        #print(f\"After up1 shape: {up2.shape}\")\n",
    "\n",
    "        up3 = self.up2(up2 + temb2, down2)\n",
    "        #print(f\"After up2 shape: {up3.shape}\")\n",
    "\n",
    "        up4 = self.up3(up3 + temb3, down1)\n",
    "        #print(f\"After up3 shape: {up4.shape}\")\n",
    "\n",
    "\n",
    "        out = self.out(torch.cat((up4, x), 1))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "# diffusion hyperparameters\n",
    "timesteps = 1000\n",
    "beta1 = 1e-4\n",
    "beta2 = 0.02\n",
    "\n",
    "# network hyperparameters\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device('cpu'))\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else torch.device('cpu'))\n",
    "n_feat = 64 # 64 hidden dimension feature\n",
    "n_cfeat = 10 # context vector is of size 10\n",
    "height = 32 # 16x16 image\n",
    "save_dir = './weights/'\n",
    "chan = 3\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 128\n",
    "n_epoch = 20\n",
    "lrate=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct DDPM noise schedule\n",
    "b_t = (beta2 - beta1) * torch.linspace(0, 1, timesteps + 1, device=device) + beta1\n",
    "a_t = 1 - b_t\n",
    "ab_t = torch.cumsum(a_t.log(), dim=0).exp()    \n",
    "ab_t[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "nn_model = ContextUnet(in_channels=chan, n_feat=n_feat, n_cfeat=n_cfeat, height=height).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5,), std=(0.5,))\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mask_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      2\u001b[0m mask_2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(trainset\u001b[38;5;241m.\u001b[39mtargets) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask_1 \u001b[38;5;241m|\u001b[39m mask_2\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'targets'"
     ]
    }
   ],
   "source": [
    "mask_1 = torch.Tensor(trainset.targets) == 3\n",
    "mask_2 = torch.Tensor(trainset.targets) == 8\n",
    "mask = mask_1 | mask_2\n",
    "trainset = torch.utils.data.Subset(trainset, torch.where(mask)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "optim = torch.optim.Adam(nn_model.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: perturbs an image to a specified noise level \n",
    "def perturb_input(x, t, noise):\n",
    "    return ab_t.sqrt()[t, None, None, None] * x + (1 - ab_t[t, None, None, None]) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weights_1000/MNIST_15-027.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load in model weights and set to eval mode\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nn_model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweights_1000/MNIST_15-027.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded in Model without context\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights_1000/MNIST_15-027.pth'"
     ]
    }
   ],
   "source": [
    "# load in model weights and set to eval mode\n",
    "nn_model.load_state_dict(torch.load(\"weights_1000/MNIST_15-027.pth\", map_location=device))\n",
    "print(\"Loaded in Model without context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After init_conv shape: torch.Size([128, 64, 32, 32])\n",
      "After down1 shape: torch.Size([128, 64, 16, 16])\n",
      "After down2 shape: torch.Size([128, 128, 8, 8])\n",
      "After down3 shape: torch.Size([128, 128, 4, 4])\n",
      "Hidden vector shape: torch.Size([128, 128, 1, 1])\n",
      "After up0 shape: torch.Size([128, 128, 4, 4])\n",
      "After up1 shape: torch.Size([128, 128, 8, 8])\n",
      "After up2 shape: torch.Size([128, 64, 16, 16])\n",
      "After up3 shape: torch.Size([128, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/79 [00:11<15:17, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After init_conv shape: torch.Size([128, 64, 32, 32])\n",
      "After down1 shape: torch.Size([128, 64, 16, 16])\n",
      "After down2 shape: torch.Size([128, 128, 8, 8])\n",
      "After down3 shape: torch.Size([128, 128, 4, 4])\n",
      "Hidden vector shape: torch.Size([128, 128, 1, 1])\n",
      "After up0 shape: torch.Size([128, 128, 4, 4])\n",
      "After up1 shape: torch.Size([128, 128, 8, 8])\n",
      "After up2 shape: torch.Size([128, 64, 16, 16])\n",
      "After up3 shape: torch.Size([128, 64, 32, 32])\n",
      "After init_conv shape: torch.Size([128, 64, 32, 32])\n",
      "After down1 shape: torch.Size([128, 64, 16, 16])\n",
      "After down2 shape: torch.Size([128, 128, 8, 8])\n",
      "After down3 shape: torch.Size([128, 128, 4, 4])\n",
      "Hidden vector shape: torch.Size([128, 128, 1, 1])\n",
      "After up0 shape: torch.Size([128, 128, 4, 4])\n",
      "After up1 shape: torch.Size([128, 128, 8, 8])\n",
      "After up2 shape: torch.Size([128, 64, 16, 16])\n",
      "After up3 shape: torch.Size([128, 64, 32, 32])\n",
      "After init_conv shape: torch.Size([128, 64, 32, 32])\n",
      "After down1 shape: torch.Size([128, 64, 16, 16])\n",
      "After down2 shape: torch.Size([128, 128, 8, 8])\n",
      "After down3 shape: torch.Size([128, 128, 4, 4])\n",
      "Hidden vector shape: torch.Size([128, 128, 1, 1])\n",
      "After up0 shape: torch.Size([128, 128, 4, 4])\n",
      "After up1 shape: torch.Size([128, 128, 8, 8])\n",
      "After up2 shape: torch.Size([128, 64, 16, 16])\n",
      "After up3 shape: torch.Size([128, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/79 [00:13<03:27,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After init_conv shape: torch.Size([128, 64, 32, 32])\n",
      "After down1 shape: torch.Size([128, 64, 16, 16])\n",
      "After down2 shape: torch.Size([128, 128, 8, 8])\n",
      "After down3 shape: torch.Size([128, 128, 4, 4])\n",
      "Hidden vector shape: torch.Size([128, 128, 1, 1])\n",
      "After up0 shape: torch.Size([128, 128, 4, 4])\n",
      "After up1 shape: torch.Size([128, 128, 8, 8])\n",
      "After up2 shape: torch.Size([128, 64, 16, 16])\n",
      "After up3 shape: torch.Size([128, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/79 [00:15<04:53,  3.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# loss is mean squared error between the predicted and true noise\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(pred_noise, noise)\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss = \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training without context code\n",
    "l_min = 1\n",
    "# set into train mode\n",
    "nn_model.train()\n",
    "\n",
    "for ep in range(n_epoch):\n",
    "    print(f'epoch {ep}')\n",
    "    \n",
    "    # linearly decay learning rate\n",
    "    optim.param_groups[0]['lr'] = lrate*(1-ep/n_epoch)\n",
    "    \n",
    "    pbar = tqdm(dataloader, mininterval=2 )\n",
    "    for x, _ in pbar:   # x: images\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perturb data\n",
    "        noise = torch.randn_like(x)\n",
    "        t = torch.randint(1, timesteps + 1, (x.shape[0],)).to(device) \n",
    "        x_pert = perturb_input(x, t, noise)\n",
    "        \n",
    "        # use network to recover noise\n",
    "        pred_noise = nn_model(x_pert, t / timesteps)\n",
    "        \n",
    "        # loss is mean squared error between the predicted and true noise\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "    print(\"Loss = \", loss.item())\n",
    "    # save model periodically\n",
    "    if ep%10==0 or ep == int(n_epoch-1) or l_min>loss.item():\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        if l_min>loss.item():\n",
    "            l_min = loss.item()\n",
    "        torch.save(nn_model.state_dict(), save_dir + f\"MNIST_{ep}.pth\")\n",
    "        print('saved model at ' + save_dir + f\"MNIST_{ep}.pth\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataloader:\n",
    "    a = x\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 3, 3, 3, 3, 8, 8, 8, 8, 3, 8, 8, 8,\n",
       "        3, 3, 3, 3, 8, 3, 8, 3, 8, 8, 8, 3, 3, 8, 8, 3, 3, 8, 3, 3, 8, 8, 3, 3,\n",
       "        3, 8, 8, 8, 8, 3, 8, 8, 3, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 8, 3, 3, 3, 3,\n",
       "        8, 3, 3, 8, 8, 8, 3, 8, 3, 8, 3, 3, 3, 3, 8, 8, 3, 3, 8, 8, 8, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 8, 3, 8, 3, 8, 3, 3, 8, 3, 3, 3, 8, 3, 8, 3, 3, 8, 3, 3,\n",
       "        3, 8, 3, 8, 3, 8, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
